{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6bd3c1-a593-49f9-94e6-e528c238ab9f",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d14478-25a3-4cd2-bd45-7f7ce4c2490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "from IPython.display import HTML, display\n",
    "from neuralop.models import FNO\n",
    "from neuralop.training import AdamW\n",
    "from neuralop.utils import count_model_params\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Local utilities\n",
    "from utils import (\n",
    "    StateTrajectoryDataset, \n",
    "    train_epoch_single_step, train_epoch_rollout,\n",
    "    rollout_state, compute_mse_over_time, print_summary,\n",
    "    save_model, load_model\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "show_animations = True\n",
    "data_truncation = 0.5\n",
    "\n",
    "plt.rcParams['animation.embed_limit'] = 500\n",
    "\n",
    "print(f\"\\033[1mUsing Device: {device}\")\n",
    "print(f\"\\033[1mShowing animations: {show_animations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d526d6-168c-46fb-803c-caaa8e3d9334",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723a1eb-72ba-4065-8e3e-019e64768e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and save as .np\n",
    "\n",
    "data_dir = \"/work/10407/anthony50102/frontera/data/hw2d_sim/t600_d256x256_raw/\"\n",
    "\n",
    "train_files = [\"hw2d_sim_step0.025_end1_pts512_c11_k015_N3_nu5e-8_20250315142044_11702_0.h5\",\n",
    "               \"hw2d_sim_step0.025_end1_pts512_c11_k015_N3_nu5e-8_20250315142045_4677_2.h5\"]\n",
    "test_files = [\"hw2d_sim_step0.025_end1_pts512_c11_k015_N3_nu5e-8_20250316215751_19984_3.h5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5d267-2dd0-43ee-8117-70aa81462367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(density, potential, gamma_n, gamma_c):\n",
    "    data = np.concatenate(\n",
    "        (np.expand_dims(density, 1), np.expand_dims(potential, 1)),\n",
    "        axis=1)\n",
    "    derived_data = np.concatenate(\n",
    "        (np.expand_dims(gamma_n, 1), np.expand_dims(gamma_c, 1)),\n",
    "        axis=1)\n",
    "\n",
    "    return data, derived_data\n",
    "\n",
    "\n",
    "processed_train_files = []\n",
    "\n",
    "for file in train_files:\n",
    "    with h5py.File(data_dir + file, 'r') as f:\n",
    "        end_index = int(f['density'].shape[0] * data_truncation)\n",
    "        density = f['density'][:end_index]\n",
    "        potential = f['phi'][:end_index]\n",
    "        gamma_n = f['gamma_n'][:end_index]\n",
    "        gamma_c = f['gamma_c'][:end_index]\n",
    "        data, derived_data = process(density, potential, gamma_n, gamma_n)\n",
    "\n",
    "        save_name = \"train_\" + \"\".join(file.split(\".\")[:-1]) + \".npz\"\n",
    "        processed_train_files.append(save_name)\n",
    "\n",
    "        np.savez(\n",
    "            save_name,\n",
    "            data=data,\n",
    "            derived_data=derived_data\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef5b28-d867-4893-99ef-a24b1bf3783b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Animation of the training data\n",
    "if show_animations:\n",
    "    train_data = np.load(processed_train_files[0])[\"data\"][::25]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    vmin = train_data[:, 0, ...].min()\n",
    "    vmax = train_data[:, 0, ...].max()\n",
    "\n",
    "    img = plt.imshow(train_data[0, 0, ...], vmin=vmin, vmax=vmax)\n",
    "\n",
    "    def animate(frame):\n",
    "        img.set_data(train_data[frame, 0, ...])\n",
    "        return [img]\n",
    "\n",
    "    plt.rcParams['animation.embed_limit'] = 500\n",
    "    animation = anim.FuncAnimation(fig, animate, frames=int(train_data.shape[0]), interval=20, blit=True)\n",
    "\n",
    "    display(HTML(animation.to_jshtml()))\n",
    "else:\n",
    "    print(\"Animation is turned off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d7158-02dc-4b26-8540-d093384b41fa",
   "metadata": {},
   "source": [
    "### Dataset and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47baa21-4944-4c2e-9f01-600e2ef7e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trajectory loader using shared Dataset class\n",
    "traj_dataset = StateTrajectoryDataset(processed_train_files[0], mode='train')\n",
    "traj_loader = DataLoader(traj_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Test\n",
    "for batch in traj_loader:\n",
    "    print(f\"Trajectory shape: {batch['data'].shape}\")  # (1, T, C, H, W)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f4108-1266-4894-9db5-7cc3950b1b57",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4750d74-d0aa-411d-a09b-e9dd9e7a3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO(\n",
    "    n_modes=(64, 64),\n",
    "    in_channels=2,\n",
    "    out_channels=2,\n",
    "    hidden_channels=512,\n",
    "    # projection_channel_ratio=2,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Count and display the number of parameters\n",
    "n_params = count_model_params(model)\n",
    "print(f\"\\nOur model has {n_params} parameters.\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2beec-b831-40ca-b8f9-60605ff9a5c7",
   "metadata": {},
   "source": [
    "### Define optim, scheduler, loss funcs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153fe31-5578-45ef-90e6-960c272b1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer (scheduler defined inline during training)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8d59d-d0aa-4767-b118-433e49a5ae4d",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a4ae0-f168-454c-8a05-47309d01eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Phase 1: Single-step training ==============\n",
    "print(\"=\" * 50)\n",
    "print(\"Phase 1: Single-step training\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "for epoch in range(100):\n",
    "    loss = train_epoch_single_step(model, traj_loader, optimizer, device)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/100, Loss: {loss:.6f}\")\n",
    "\n",
    "# ============== Phase 2: Curriculum rollout training ==============\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Phase 2: Curriculum rollout training\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "rollout_schedule = [\n",
    "    (5, 0.0, 20),    # (rollout_len, scheduled_sampling_prob, epochs)\n",
    "    (10, 0.2, 20),\n",
    "    (20, 0.4, 20),\n",
    "    (40, 0.6, 20),\n",
    "    (80, 0.8, 30),\n",
    "]\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "for rollout_len, ss_prob, n_epochs in rollout_schedule:\n",
    "    print(f\"\\n--- Rollout: {rollout_len}, Scheduled Sampling: {ss_prob} ---\")\n",
    "    for epoch in range(n_epochs):\n",
    "        loss = train_epoch_rollout(model, traj_loader, optimizer, device, rollout_len, ss_prob)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{n_epochs}, Loss: {loss:.6f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2cec59-dac8-469f-a726-e55025f5a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model with metadata\n",
    "save_model(model, 'state_model', metadata={\n",
    "    'architecture': 'FNO',\n",
    "    'n_modes': (64, 64),\n",
    "    'hidden_channels': 512,\n",
    "    'final_rollout': 80,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5827b4e2-b04c-412e-a948-33d7eb701d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     n_epochs=15,\n",
    "#     device=device,\n",
    "#     wandb_log=False,  # Disable Weights & Biases logging for this tutorial\n",
    "#     eval_interval=5,  # Evaluate every 5 epochs\n",
    "#     use_distributed=False,  # Single GPU/CPU training\n",
    "#     verbose=True,  # Print training progress\n",
    "# )\n",
    "\n",
    "# train_loader, test_loaders, data_processor = load_darcy_flow_small(\n",
    "#     n_train=1000,\n",
    "#     batch_size=64,\n",
    "#     n_tests=[100, 50],\n",
    "#     test_resolutions=[16, 32],\n",
    "#     test_batch_sizes=[32, 32],\n",
    "# )\n",
    "\n",
    "# trainer.train(\n",
    "#     train_loader=train_loader,\n",
    "#     test_loaders={256:test_loader},\n",
    "#     optimizer=optimizer,\n",
    "#     scheduler=scheduler,\n",
    "#     regularizer=False,\n",
    "#     training_loss=train_loss,\n",
    "#     eval_losses=eval_losses,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e30a6c-1bd2-467a-9ad5-d69d92438393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset and run rollout evaluation\n",
    "full_data = np.load(processed_train_files[0])[\"data\"]\n",
    "print(f\"Full data shape: {full_data.shape}\")\n",
    "\n",
    "# Split\n",
    "total_steps = full_data.shape[0]\n",
    "train_end = int(total_steps * 0.8)\n",
    "val_end = train_end + int((total_steps - train_end) * 0.5)\n",
    "\n",
    "train_data = full_data[:train_end]\n",
    "test_data = full_data[val_end:]\n",
    "\n",
    "# Run rollouts using shared utility\n",
    "train_recon = rollout_state(model, train_data[0], len(train_data), device)\n",
    "test_recon = rollout_state(model, test_data[0], len(test_data), device)\n",
    "\n",
    "print(f\"Train recon shape: {train_recon.shape}\")\n",
    "print(f\"Test recon shape: {test_recon.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616739e5-7e10-47ea-956c-72a1c442d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_animations:\n",
    "    print(\"\\033[1mShowing animation\")\n",
    "    # Subsample\n",
    "    train_data_subbed = train_data[::5]\n",
    "    train_recon_subbed = train_recon[::5]\n",
    "\n",
    "    # Figure + axes\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    t_vmin = train_data_subbed[:, 0].min()\n",
    "    t_vmax = train_data_subbed[:, 0].max()\n",
    "    # r_vmin = train_recon_subbed[:, 0].min()\n",
    "    # r_vmax = train_recon_subbed[:, 0].max()\n",
    "\n",
    "    # Create the images on the correct axes\n",
    "    img = ax[0].imshow(train_data_subbed[0, 0], vmin=t_vmin, vmax=t_vmax)\n",
    "    img2 = ax[1].imshow(train_recon_subbed[0, 0])\n",
    "\n",
    "    ax[0].set_title(\"Ground Truth\")\n",
    "    ax[1].set_title(\"Reconstruction\")\n",
    "\n",
    "\n",
    "    # Animation function\n",
    "    def animate(frame):\n",
    "        img.set_data(train_data_subbed[frame, 0])\n",
    "        img2.set_data(train_recon_subbed[frame, 0])\n",
    "        return [img, img2]\n",
    "\n",
    "\n",
    "    animation = anim.FuncAnimation(\n",
    "        fig,\n",
    "        animate,\n",
    "        frames=train_data_subbed.shape[0],\n",
    "        interval=20,\n",
    "        blit=True\n",
    "    )\n",
    "\n",
    "    display(HTML(animation.to_jshtml()))\n",
    "else:\n",
    "    print(\"Not showing animations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation using shared utilities\n",
    "train_losses = compute_mse_over_time(train_data, train_recon)\n",
    "test_losses = compute_mse_over_time(test_data, test_recon)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(train_losses)\n",
    "axes[0].set_xlabel('Timestep')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('Training Data: Rollout Error Over Time')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(test_losses, color='orange')\n",
    "axes[1].set_xlabel('Timestep')\n",
    "axes[1].set_ylabel('MSE Loss')\n",
    "axes[1].set_title('Test Data: Rollout Error Over Time')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary stats\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print_summary(\"Train\", train_losses)\n",
    "print_summary(\"Test\", test_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IEEE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
